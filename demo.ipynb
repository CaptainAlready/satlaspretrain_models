{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7184fcc7-2191-4372-8123-5d4d7e1b32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This demonstrates how to finetune a SatlasPretrain Sentinel-2 model on the EuroSAT classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa84559a-c8e3-4e0b-9407-a8bf11d40ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "import requests\n",
    "import torch.nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import satlaspretrain_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8102535-1af5-48e1-9cf2-4a4b5f72d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Download the EuroSAT_RGB dataset.\n",
    "# Only go through the downloading and unzipping process if it hasn't been done before.\n",
    "if not os.path.exists('EuroSAT_RGB/'):\n",
    "    # Download the EuroSAT_RGB dataset. This is a zip file.\n",
    "    zip_file_url = 'https://zenodo.org/records/7711810/files/EuroSAT_RGB.zip?download=1'\n",
    "\n",
    "    # Send a GET request to the EuroSAT_RGB Zenodo download URL.\n",
    "    response = requests.get(zip_file_url)\n",
    "\n",
    "    # Check if the request was successful.\n",
    "    if response.status_code == 200:\n",
    "        # Use BytesIO for the zip file content.\n",
    "        zip_file = io.BytesIO(response.content)\n",
    "\n",
    "        # Open the zip file. You should see the EuroSAT_RGB/ folder in this directory.\n",
    "        with zipfile.ZipFile(zip_file) as zfile:\n",
    "            # Extract all the contents into the current directory\n",
    "            zfile.extractall('.')\n",
    "            print(\"Zip file extracted successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download the zip file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac09664-e0cd-4ddc-b358-f3be8e6dabe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes mapped to integers: {'Highway': 0, 'River': 1, 'PermanentCrop': 2, 'HerbaceousVegetation': 3, 'SeaLake': 4, 'Pasture': 5, 'Forest': 6, 'Industrial': 7, 'AnnualCrop': 8, 'Residential': 9}\n"
     ]
    }
   ],
   "source": [
    "# Gather the EuroSAT class names.\n",
    "classes = os.listdir('EuroSAT_RGB/')\n",
    "\n",
    "# Create a mapping from class label to a unique integer. For later visualization.\n",
    "cls_to_int = {label: idx for idx, label in enumerate(set(classes))}\n",
    "int_to_class = {v: k for k, v in cls_to_int.items()}\n",
    "print(\"Classes mapped to integers:\", cls_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d495b9da-c92a-4000-9b88-fea5754e12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset class that takes in the path to the EuroSAT_RGB path and returns datapoints,\n",
    "# each with a torch tensor containing the image data and a corresponding target class. \n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, dataset_path, val=False):\n",
    "\n",
    "        self.datapoints = []\n",
    "\n",
    "        # The subdirectories in the dataset folder are named by class.\n",
    "        classes = os.listdir(dataset_path)\n",
    "\n",
    "        # Create a mapping from class label to a unique integer.\n",
    "        cls_to_int = {label: idx for idx, label in enumerate(set(classes))}\n",
    "        \n",
    "        # For each class, use 80% of the images for training and the rest for validation.\n",
    "        for cls in classes:\n",
    "            cls_int = cls_to_int[cls]\n",
    "            cls_imgs = os.listdir(dataset_path + '/' + cls + '/')\n",
    "\n",
    "            if val:\n",
    "                cls_datapoints = [(dataset_path + '/' + cls + '/' + img, cls_int) for img in cls_imgs[2400:]]\n",
    "            else:\n",
    "                cls_datapoints = [(dataset_path + '/' + cls + '/' + img, cls_int) for img in cls_imgs[:2400]]\n",
    "\n",
    "            self.datapoints += cls_datapoints\n",
    "        print(\"Loaded \", len(self.datapoints), \" datapoints.\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, cls_int = self.datapoints[idx]\n",
    "        img = torchvision.io.read_image(img_path)  # load image directly into a [3, 64, 64] tensor\n",
    "        img = img.float() / 255  # normalize input to be between 0-1\n",
    "        target = torch.tensor(cls_int)  # convert class index into a torch tensor\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e7fbd4-9ee9-4241-975f-b40466918deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment arguments.\n",
    "device = torch.device('cpu')\n",
    "num_epochs = 1000\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "val_step = 10  # evalaute every val_step epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c94c577-3473-4362-808e-5479936c79ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  23600  datapoints.\n",
      "Loaded  3400  datapoints.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the train and validation datasets.\n",
    "train_dataset = Dataset('EuroSAT_RGB/')\n",
    "val_dataset = Dataset('EuroSAT_RGB/', val=True)\n",
    "\n",
    "# Dataloaders.\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45547e65-bceb-4506-9766-8cbb948bb66b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize a couple datapoints, pulled randomly from the training set.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m shuffled_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandperm(train_dataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m())\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      6\u001b[0m random_samples \u001b[38;5;241m=\u001b[39m [train_dataset[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m shuffled_indices]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Visualize a couple datapoints, pulled randomly from the training set.\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shuffled_indices = torch.randperm(train_dataset.__len__()).tolist()\n",
    "random_samples = [train_dataset[x] for x in shuffled_indices]\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    data, target = random_samples[i]\n",
    "    \n",
    "    image = data.cpu().numpy()\n",
    "    target = int(target.cpu().numpy())    \n",
    "    image = image.transpose(1, 2, 0)\n",
    "\n",
    "    ax.set_title(int_to_class[target], fontsize=10)\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c509f-9422-4d88-9209-d45a8ef0035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a pretrained model, using the SatlasPretrain single-image Swin-v2-Base Sentinel-2 image model weights\n",
    "# with a classification head with num_categories=10, since EuroSAT has 10 classes.\n",
    "weights_manager = satlaspretrain_models.Weights()\n",
    "model = weights_manager.get_pretrained_model(\"Sentinel2_SwinB_SI_RGB\", fpn=True, head=satlaspretrain_models.Head.CLASSIFY, \n",
    "                                                num_categories=10, device='cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf29b9-951a-4320-a6cd-dbf7bafcdb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e2b82-6ba1-4b20-8025-695c3fabb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop.\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Starting Epoch...\", epoch)\n",
    "\n",
    "    for data, target in train_dataloader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output, loss = model(data)\n",
    "        print(\"Train Loss = \", loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation.\n",
    "    if epoch % val_step == 0:\n",
    "        model.eval()\n",
    "\n",
    "        for val_data, val_target in val_dataloader:\n",
    "            val_data = val_data.to(device)\n",
    "            val_target = val_target.to(device)\n",
    "\n",
    "            val_output, val_loss = model(val_data)\n",
    "\n",
    "            val_accuracy = (val_output.argmax(dim=1) == val_target).float().mean().item()\n",
    "            print(\"Validation accuracy = \", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c49ad28-5c78-4955-9742-eabd0a82a4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a73d3-1df8-4f66-9032-eaf504fdecd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
